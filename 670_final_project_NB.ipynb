{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv('WikiLarge_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def tokenizer(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "  \n",
    "def remove_stopwords(review):\n",
    "    all_word = []\n",
    "    for sentence in tqdm(review):\n",
    "        all_word_list = []\n",
    "        for token in sentence:\n",
    "            if nlp.vocab[token].is_stop == True:\n",
    "                continue\n",
    "            else:\n",
    "                all_word_list.append(token)\n",
    "        all_word.append(\" \".join(all_word_list))    \n",
    "        \n",
    "    return all_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "rest_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def tokenizer(text):\n",
    "    return rest_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def result_evalation(predict_result, true_result):\n",
    "    print(\"accuracy:\", accuracy_score(true_result, predict_result))\n",
    "    print(\"precision:\", precision_score(true_result, predict_result))\n",
    "    print(\"recall:\", recall_score(true_result, predict_result))\n",
    "    print(\"f1:\", f1_score(true_result, predict_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:08<00:00, 47889.75it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text=[]\n",
    "for i in range(len(all_data)):\n",
    "    tokenized_text.append(tokenizer(all_data['original_text'][i]))\n",
    "tokenized_text_new=remove_stopwords(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['tokenize']=tokenized_text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss= StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(all_data, all_data['label']):\n",
    "    strat_train_set=all_data.iloc[train_index]\n",
    "    strat_dev_set=all_data.iloc[test_index]\n",
    "strat_dev_set['label'].value_counts()/len(strat_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('WikiLarge_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label\n",
       "0            0         -2011    NaN\n",
       "1            1         -2011    NaN\n",
       "2            2         -2000    NaN\n",
       "3            3         -1997    NaN\n",
       "4            4         1.636    NaN\n",
       "...        ...           ...    ...\n",
       "119087  119087        #NAME?    NaN\n",
       "119088  119088        #NAME?    NaN\n",
       "119089  119089        #NAME?    NaN\n",
       "119090  119090        #NAME?    NaN\n",
       "119091  119091        #NAME?    NaN\n",
       "\n",
       "[119092 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.reset_index(inplace=True)\n",
    "strat_dev_set.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_is_simple=[]\n",
    "train_word_is_not_simple=[]\n",
    "train_label=strat_train_set['label'].tolist()\n",
    "train_text_no_punc=strat_train_set['tokenize'].tolist()\n",
    "dev_label=strat_dev_set['label'].tolist()\n",
    "dev_text_no_punc=strat_dev_set['tokenize'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(strat_train_set)):\n",
    "    if int(train_label[i])==1:\n",
    "        train_word_is_not_simple.extend(tokenizer(train_text_no_punc[i]))\n",
    "    else:\n",
    "        train_word_is_simple.extend(tokenizer(train_text_no_punc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_size=len(set(train_word_is_not_simple+train_word_is_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_y1=train_label.count(1)/len(train_label)\n",
    "p_y0=train_label.count(0) / len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "train_text_word_counts_not_simple=Counter(train_word_is_not_simple)\n",
    "\n",
    "train_text_word_counts_simple=Counter(train_word_is_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(y_j,\n",
    "          x_i,\n",
    "          smoothing_alpha=1):\n",
    "\n",
    "    smoothing_additive = smoothing_alpha * train_word_size\n",
    "    if int(y_j) == 1:\n",
    "        try:\n",
    "            return (train_text_word_counts_not_simple[x_i] + smoothing_alpha\n",
    "                ) / (len(train_word_is_not_simple) + smoothing_additive)\n",
    "        except:\n",
    "            return (( smoothing_alpha\n",
    "                ) / (len(train_word_is_not_simple) + smoothing_additive))\n",
    "            \n",
    "    if int(y_j) == 0:\n",
    "        try :\n",
    "            return (train_text_word_counts_simple[x_i] + smoothing_alpha) / (\n",
    "            len(train_word_is_simple) + smoothing_additive)\n",
    "        except:\n",
    "            return (  smoothing_alpha) / (\n",
    "            len(train_word_is_simple) + smoothing_additive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(word_list,smoothing_alpha):\n",
    "    word_seperated=tokenizer(word_list)\n",
    "    word_seperated_no_stop=word_seperated\n",
    "    #for word in word_seperated:\n",
    "     #   if word not in STOP_WORDS:\n",
    "      #      word_seperated_no_stop.append(word)\n",
    "    p_x_y0=np.log(p_y0)\n",
    "   # print(p_x_y0)\n",
    "    p_x_y1=np.log(p_y1)\n",
    "   # print(p_x_y1)\n",
    "    for i in range(len(word_seperated_no_stop)):\n",
    "        temp1=train(0,word_seperated_no_stop[i],smoothing_alpha)\n",
    "        #print(temp1)\n",
    "        temp2=train(1,word_seperated_no_stop[i],smoothing_alpha)\n",
    "        #print(temp2)\n",
    "        if temp1==0 and temp2!=0:\n",
    "            #print(\"yes\")\n",
    "            return 1\n",
    "        if temp2==0 and temp1!=0:\n",
    "            #print(\"no\")\n",
    "            return 0\n",
    "        if temp1!=0 and temp2!=0:\n",
    "            p_x_y0=p_x_y0+np.log(temp1)\n",
    "            p_x_y1=p_x_y1+np.log(temp2)\n",
    "        if temp1==0 and temp2==0:\n",
    "            # both numerators are 0\n",
    "            return np.random.binomial(1,probability,1)[0]\n",
    "    if(p_x_y0>p_x_y1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result_dev=[]\n",
    "for smoothing_alpha in [1]:\n",
    "    for i in range(len(dev_text_no_punc)):\n",
    "        temp=classify(dev_text_no_punc[i],smoothing_alpha)\n",
    "        predict_result_dev.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5762290951843942\n",
      "precision: 0.574069756597967\n",
      "recall: 0.5908054802409003\n",
      "f1: 0.5823173976279724\n"
     ]
    }
   ],
   "source": [
    "result_evalation(predict_result_dev,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119092/119092 [00:01<00:00, 83679.57it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text_test=[]\n",
    "for i in range(len(test_data)):\n",
    "    tokenized_text_test.append(tokenizer(test_data['original_text'][i]))\n",
    "tokenized_text_test=remove_stopwords(tokenized_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result_test=[]\n",
    "for smoothing_alpha in [1]:\n",
    "    for i in range(len(tokenized_text_test)):\n",
    "        temp=classify(tokenized_text_test[i],smoothing_alpha)\n",
    "        predict_result_test.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1=pd.DataFrame({'id':list(test_data['id']), 'label':predict_result_test})\n",
    "result_1.to_csv('results_NB.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
